{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from gensim.models import Word2Vec\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = Word2Vec.load('./sentimentAnalysis/models/word2vec.model')\n",
    "s_analysis_model = load_model('./sentimentAnalysis/models/lstm_model.h5')\n",
    "\n",
    "\n",
    "with open('./sentimentAnalysis/models/word_tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "SEQUENCE_LENGTH = 300\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "\n",
    "\n",
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:        \n",
    "        label = NEUTRAL\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE\n",
    "    \n",
    "    \n",
    "def predict_sentiment(text, include_neutral=True):\n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "    # Predict\n",
    "    score = word2vec_model.predict([x_test])[0]\n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
    "\n",
    "    return {\"label\": label, \"score\": float(score)}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"Behaviorial\", \"Body Image\", \"Grief\", \"Relationship\", \"Depression\", \"Physical\"]\n",
    "\n",
    "\n",
    "behaviorial_keywords = [\"sleep\", \"ocd\", \"anxiety\", \"control\", \"mood\", \"behavior\", \"uncontrollable\", \"anger\", \"compulsory\"]\n",
    "body_image_keywords = [\"fat\", \"skinny\", \"obese\", \"ugly\", \"acne\", \"unpopular\", \"body\", \"eating\", \"drinking\", \"weight\"]\n",
    "grief_keywords = [\"grief\", \"loss\", \"sadness\", \"death\", \"regret\", \"shock\", \"denial\", \"disbelief\", \"overwhelmed\"]\n",
    "relationship_keywords = [\"cheat\", \"feelings\", \"love\", \"boyfriend\", \"girlfriend\", \"wife\", \"husband\", \"relations\", \"friend\", \"trauma\", \"abuse\", \"trust\"]\n",
    "depression_keywords = [\"depression\", \"suicide\", \"kill\", \"death\", \"misery\", \"motivation\", \"stress\", \"lonely\", \"illness\", \"drugs\"]\n",
    "physical_keywords = [\"burn\", \"pain\", \"hurt\", \"physical\", \"surgery\", \"broken\", \"tear\", \"sprain\", \"blood\", \"bone\", \"ache\", \"walk\", \"rest\"]\n",
    "\n",
    "therapy_category_keywords = [behaviorial_keywords, body_image_keywords, grief_keywords, relationship_keywords, depression_keywords, physical_keywords]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Max\n",
      "[nltk_data]     Xiao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relationship\n",
      "{'behaviorial': 0.5422804057598114, 'body_image': 0.704825222492218, 'grief': 0.572041928768158, 'relationship': 0.9723409116268158, 'depression': 0.6548178493976593, 'physical': 0.583156019449234}\n"
     ]
    }
   ],
   "source": [
    "test_input = \"I like children\"\n",
    "\n",
    "#calculates similiarity score between each word in the input and each keyword for the categories\n",
    "#each categories top 2 words similarity scores are added up. Whichever categories sum is highest is the category for the sentence.\n",
    "\n",
    "def categorize_problem(input):\n",
    "    \n",
    "    behaviorial_similiarity = []\n",
    "    body_image_similiarity = []\n",
    "    grief_similiarity = []\n",
    "    relationship_similiarity = []\n",
    "    depression_similarity = []\n",
    "    physical_similiarity = []\n",
    "\n",
    "    \n",
    "    input_tokens = preprocess(input)\n",
    "    \n",
    "    for keyword_list in therapy_category_keywords:\n",
    "        category_index = therapy_category_keywords.index(keyword_list)\n",
    "        \n",
    "        for word in input_tokens: \n",
    "            \n",
    "            try:\n",
    "                word2vec_model.wv.similarity(word, \"hi\")\n",
    "            except KeyError as e:\n",
    "                return (\"Spell Check Your Words Please\")\n",
    "            \n",
    "            word_similarity_score = [(word, word2vec_model.wv.similarity(word, keyword), keyword) for keyword in keyword_list]\n",
    "            \n",
    "            if category_index == 0:\n",
    "                behaviorial_similiarity.append(word_similarity_score)\n",
    "                behaviorial_similiarity = [sorted(x, key = lambda x: x[1], reverse= True) for x in behaviorial_similiarity]\n",
    "            elif category_index == 1:\n",
    "                body_image_similiarity.append(word_similarity_score)\n",
    "                body_image_similiarity = [sorted(x, key = lambda x: x[1], reverse= True) for x in body_image_similiarity]\n",
    "            elif category_index == 2:\n",
    "                grief_similiarity.append(word_similarity_score)\n",
    "                grief_similiarity = [sorted(x, key = lambda x: x[1], reverse= True) for x in grief_similiarity]\n",
    "            elif category_index == 3:\n",
    "                relationship_similiarity.append(word_similarity_score)\n",
    "                relationship_similiarity = [sorted(x, key = lambda x: x[1], reverse= True) for x in relationship_similiarity]\n",
    "            elif category_index == 4:\n",
    "                depression_similarity.append(word_similarity_score)\n",
    "                depression_similarity = [sorted(x, key = lambda x: x[1], reverse= True) for x in depression_similarity]\n",
    "            elif category_index == 5:\n",
    "                physical_similiarity.append(word_similarity_score)\n",
    "                physical_similiarity = [sorted(x, key = lambda x: x[1], reverse= True) for x in physical_similiarity]\n",
    "    \n",
    "    \n",
    "    category_similarity_scores = {\n",
    "        'behaviorial'  : 0,\n",
    "        'body_image'   : 0,\n",
    "        'grief'        : 0,\n",
    "        'relationship' : 0,\n",
    "        'depression'   : 0,\n",
    "        'physical'     : 0\n",
    "    }\n",
    "    \n",
    "    for i in behaviorial_similiarity:\n",
    "        category_similarity_scores['behaviorial']  += i[0][1] + i[1][1] #The score for input word to top 2 keywords. Example Keeps = bheavior + sleep = 0.3.\n",
    "    for i in body_image_similiarity:\n",
    "        category_similarity_scores['body_image']   += i[0][1] + i[1][1]\n",
    "    for i in grief_similiarity:\n",
    "        category_similarity_scores['grief']        += i[0][1] + i[1][1]\n",
    "    for i in relationship_similiarity:\n",
    "        category_similarity_scores['relationship'] += i[0][1] + i[1][1]\n",
    "    for i in depression_similarity:\n",
    "        category_similarity_scores['depression']   += i[0][1] + i[1][1]\n",
    "    for i in physical_similiarity:\n",
    "        category_similarity_scores['physical']     += i[0][1] + i[1][1]\n",
    "    \n",
    "    category = max(category_similarity_scores, key=category_similarity_scores.get)\n",
    "\n",
    "    \n",
    "    return [category, category_similarity_scores]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relationship\n",
      "{'behaviorial': 0.4313633143901825, 'body_image': 0.7539129592478275, 'grief': 0.5382664278149605, 'relationship': 1.2951907217502594, 'depression': 0.5709313675761223, 'physical': 0.51666110008955}\n"
     ]
    }
   ],
   "source": [
    "test_input = ('hi i like children')\n",
    "\n",
    "output = categorize_problem(test_input)\n",
    "for i in output:\n",
    "    print(i)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.4rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96cec487207b392fa9d2d5631fb8426bf20c81886020bda584338f1114db8ee4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
